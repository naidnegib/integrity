{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Notebook\n",
    "\n",
    "Jupyter notebook used to test and document Analyze operations performed by analyze.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializations\n",
    "\n",
    "Required initalizations and configurations. \n",
    "\n",
    "Please, **note that file names have to be set to proper values and left clear before submitting code to repos**. Exceptions, such as 'File not found', are not controlled for clarity purporses.\n",
    "\n",
    "### CSV Structure\n",
    "\n",
    "Fields in CSV files are: `PATH;FILENAME;SIZE;CHANGED;HASH;PREV_HASH;DATE;MODIFICATION`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "VALUE_DEFAULT_SEPARATOR = ';'\n",
    "TXT_O_CSV_HEADER = \"PATH;FILENAME;SIZE;CHANGED;HASH;PREV_HASH;DATE;MODIFICATION\"\n",
    "\n",
    "\n",
    "filename1 = \"tests\\\\test.csv\"\n",
    "filename2 = \"tests\\\\testBitrot.csv\"\n",
    "\n",
    "# Load CSV files as dataframes\n",
    "df_file1 = pd.read_csv(filename1, sep=VALUE_DEFAULT_SEPARATOR)\n",
    "df_file2 = pd.read_csv(filename2, sep=VALUE_DEFAULT_SEPARATOR)\n",
    "\n",
    "# Append a new column with the source CSV used\n",
    "df_file1 = df_file1.assign(SOURCE=filename1)\n",
    "df_file2 = df_file2.assign(SOURCE=filename2)\n",
    "\n",
    "# Dataframe to return with selected items\n",
    "#df_return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for duplicated files\n",
    "\n",
    "One entry is a duplicated file when values in both entries (hash,filesize) are the same. Yoy can not only rely on hash due to conflicts.\n",
    "\n",
    "### CASE 1. Files marked as `CHANGED` are candidates to have suffered Bit-rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modified_files1 = df_file1[df_file1['CHANGED']]\n",
    "df_modified_files2 = df_file2[df_file2['CHANGED']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CASE 2. Files with same relevant information but different `HASH`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join identical files to search Hash differences\n",
    "df_file1['MarkerFull'] = df_file1['SIZE'].astype(str) + '|' + df_file1['MODIFICATION'] + '|' + df_file1['PATH'] + \"\\\\\" + df_file1['FILENAME'] \n",
    "df_file2['MarkerFull'] = df_file2['SIZE'].astype(str) + '|' + df_file2['MODIFICATION'] + '|' + df_file2['PATH'] + \"\\\\\" + df_file2['FILENAME'] \n",
    "df_joint = df_file1.set_index('MarkerFull').join(df_file2.set_index('MarkerFull'), rsuffix='_2')\n",
    "\n",
    "df_diff_hash = df_joint[(df_joint['HASH'] != df_joint['HASH_2'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CASE 3. Files with same relevant information, different `PATH` (moved or under different folder tree structure) and different `HASH`\n",
    "We assume that if the file name has been changed we have modified the file and shouldn't be considered to have been bit-rotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NOT WORKING STILL!!!\n",
    "df_file1['MarkerName'] = df_file1['SIZE'].astype(str) + '|' + df_file1['MODIFICATION'] + '|' + df_file1['FILENAME'] \n",
    "df_file2['MarkerName'] = df_file2['SIZE'].astype(str) + '|' + df_file2['MODIFICATION'] + '|' + df_file2['FILENAME'] \n",
    "df_joint = df_file1.set_index('MarkerName').join(df_file2.set_index('MarkerFull'), rsuffix='_2')\n",
    "\n",
    "df_diff_name_hash = df_joint[(df_joint['HASH'] != df_joint['HASH_2'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option 1: using a dataframe with duplicated Ids to look for duplicated hashes\n",
    "#hashes = df_file1[\"HASH\"]\n",
    "#df_file1_duplicated_hashes = df_file1[hashes.isin(hashes[hashes.duplicated()])]\n",
    "#df_file1_single_hashes = df_file1[~hashes.isin(hashes[hashes.duplicated()])] # The other part of the files\n",
    "\n",
    "#Option 2: Duplicated values grouped by hash and file size (slower)\n",
    "#df_file1_grouped_duplicates = pd.concat(g for _, g in df_file1.groupby([\"HASH\", \"SIZE\"]) if len(g) > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_modified_files = df_everything[df_everything['CHANGED']]   # Maintain all the columns\n",
    "#df_modified_files = df_everything.loc[df_everything['CHANGED'], [\"PATH\", \"FILENAME\", \"SIZE\", \"HASH\", \"MODIFICATION\", \"SOURCE\"]] # Maintain only selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining tests\n",
    "#df = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'], 'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n",
    "#other = pd.DataFrame({'key': ['K0', 'K1', 'K2'], 'A': ['B0', 'B1', 'B2']})\n",
    "#d1=df.join(other, lsuffix='_caller', rsuffix='_other')\n",
    "#d2=df.set_index('key').join(other.set_index('key'), lsuffix='_caller', rsuffix='_other')\n",
    "#d3=df.join(other.set_index('key'), on='key', lsuffix='_caller', rsuffix='_other')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "edc939acd62d86c9c91ac516ea8cb39a9a70c4b1555e1f0f53de9c3f7135ad5a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
